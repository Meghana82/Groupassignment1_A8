# -*- coding: utf-8 -*-
"""Dyson_Airwrap_Sentiment_App.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18BHSCkG5HWwX807yvO0EJwmpPS5OVwDJ
"""

!pip install supabase pandas

from supabase import create_client
import pandas as pd

SUPABASE_URL = "https://bxqkumrkqsikzmlpatwd.supabase.co"
SUPABASE_KEY = "sb_publishable_YBO6o7OYfxde_hMSaB6cLA_48gcRXDe"

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# Fetch comments
response = supabase.table("comments").select("*").execute()

df = pd.DataFrame(response.data)
df.head()

!pip install textblob

from textblob import TextBlob

def get_sentiment(text):
    polarity = TextBlob(text).sentiment.polarity
    if polarity > 0:
        return "Positive"
    else:
        return "Negative"

df["sentiment"] = df["comment_text"].astype(str).apply(get_sentiment)

df[["comment_text", "sentiment"]].head()

!pip -q install gradio matplotlib



!pip -q install transformers torch

from transformers import pipeline
import pandas as pd

sentiment_pipe = pipeline("sentiment-analysis")

def hf_sentiment(text):
    if not isinstance(text, str) or text.strip() == "":
        return "Neutral"
    out = sentiment_pipe(text[:512])[0]  # limit length
    label = out["label"].upper()
    if "NEG" in label:
        return "Negative"
    elif "POS" in label:
        return "Positive"
    else:
        return "Neutral"

df["sentiment"] = df["comment_text"].astype(str).apply(hf_sentiment)

df[["comment_text", "sentiment"]].head(10)

from transformers import pipeline

sentiment_pipe = pipeline("sentiment-analysis")

def hf_sentiment_with_score(text):
    if not isinstance(text, str) or text.strip() == "":
        return ("Neutral", 0.0)
    out = sentiment_pipe(text[:512])[0]
    label = out["label"].upper()
    score = float(out["score"])
    if "NEG" in label:
        return ("Negative", score)
    elif "POS" in label:
        return ("Positive", score)
    else:
        return ("Neutral", score)

sent = df["comment_text"].astype(str).apply(hf_sentiment_with_score)
df["sentiment"] = sent.apply(lambda x: x[0])
df["sentiment_confidence"] = sent.apply(lambda x: x[1])

# Now "top" means highest confidence
top_pos = df[df["sentiment"]=="Positive"].sort_values("sentiment_confidence", ascending=False).head(2)
top_neg = df[df["sentiment"]=="Negative"].sort_values("sentiment_confidence", ascending=False).head(2)

top_pos[["comment_text","sentiment_confidence"]], top_neg[["comment_text","sentiment_confidence"]]

!pip -q install transformers torch

from transformers import pipeline

sentiment_pipe = pipeline("sentiment-analysis")  # model auto-selected

def hf_sentiment_with_score(text):
    text = "" if text is None else str(text)
    text = text.strip()
    if not text:
        return ("Neutral", 0.0)
    out = sentiment_pipe(text[:512])[0]
    label = out["label"].upper()
    score = float(out["score"])
    if "NEG" in label:
        return ("Negative", score)
    if "POS" in label:
        return ("Positive", score)
    return ("Neutral", score)

tmp = df["comment_text"].apply(hf_sentiment_with_score)
df["sentiment"] = tmp.apply(lambda x: x[0])
df["sentiment_confidence"] = tmp.apply(lambda x: x[1])

df[["comment_text","sentiment","sentiment_confidence"]].head(10)

response = supabase.table("v_comments_joined").select("*").execute()
df = pd.DataFrame(response.data)
df.head()

!pip -q install gradio pandas matplotlib supabase textblob

import gradio as gr
import pandas as pd
import matplotlib.pyplot as plt
from supabase import create_client
from textblob import TextBlob

# ======================
# 1) Supabase connection
# ======================
SUPABASE_URL = "https://bxqkumrkqsikzmlpatwd.supabase.co"
SUPABASE_KEY = "sb_publishable_YBO6o7OYfxde_hMSaB6cLA_48gcRXDe"
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# ======================
# 2) Load data
# ======================
def load_df():
    for table in ["v_comments_joined", "comments"]:
        try:
            resp = supabase.table(table).select("*").execute()
            if resp.data:
                dff = pd.DataFrame(resp.data)
                dff["__source__"] = table
                return dff
        except Exception:
            pass
    return pd.DataFrame()

df = load_df()

if len(df) == 0:
    raise ValueError("No data loaded from Supabase.")

# Ensure required base columns
BASE_COLS = ["comment_id", "comment_text", "published_at"]
for c in BASE_COLS:
    if c not in df.columns:
        raise ValueError(f"Missing required column: {c}")

df["published_at"] = pd.to_datetime(df["published_at"], errors="coerce")
df = df.dropna(subset=["published_at", "comment_text"])

# ======================
# 3) Sentiment (create if missing)
# ======================
def compute_sentiment(text):
    try:
        return "Positive" if TextBlob(text).sentiment.polarity > 0 else "Negative"
    except:
        return "Negative"

if "sentiment" not in df.columns:
    df["sentiment"] = df["comment_text"].apply(compute_sentiment)

df["sentiment_score"] = df["sentiment"].apply(lambda x: 1 if x == "Positive" else 0)

# ======================
# 4) UI labels
# ======================
STANCE_LABELS = {
    "All Videos": None,
    "Supportive Reviews": "fanboy",
    "Skeptical Reviews": "critical"
}

def empty_fig(title):
    fig = plt.figure()
    plt.title(title)
    plt.text(0.5, 0.5, "No data for this filter", ha="center", va="center")
    plt.axis("off")
    return fig

def get_filtered_df(label):
    if "stance" not in df.columns:
        return df.copy(), "‚ö†Ô∏è stance not available (filter disabled)"
    raw = STANCE_LABELS[label]
    if raw is None:
        return df.copy(), None
    return df[df["stance"] == raw].copy(), None

# ======================
# 5) App logic
# ======================


def empty_fig(title: str, msg: str = "No data for this filter"):
    fig = plt.figure()
    plt.title(title)
    plt.text(0.5, 0.5, msg, ha="center", va="center")
    plt.axis("off")
    plt.tight_layout()
    return fig

def refresh(display_choice, n):
    n = int(n)

    # 1) Filter safely
    dff, warn = get_filtered_df(display_choice)   # uses your mapping + stance guard

    if dff is None or len(dff) == 0:
        status = f"Video Type: {display_choice} | Rows: 0"
        if warn: status += f" | {warn}"
        return (
            empty_fig("Sentiment Trend (Weekly)"),
            empty_fig("Comment Volume (Weekly)"),
            "No positive comments for this filter.",
            "No negative comments for this filter.",
            status
        )

    # 2) Ensure datetime exists + valid
    dff["published_at"] = pd.to_datetime(dff["published_at"], errors="coerce")
    dff = dff.dropna(subset=["published_at", "comment_text"])

    if len(dff) == 0:
        status = f"Video Type: {display_choice} | Rows: 0 (no valid dated comments)"
        if warn: status += f" | {warn}"
        return (
            empty_fig("Sentiment Trend (Weekly)", "No valid dates"),
            empty_fig("Comment Volume (Weekly)", "No valid dates"),
            "No positive comments for this filter.",
            "No negative comments for this filter.",
            status
        )

    # 3) sentiment_score if missing
    if "sentiment_score" not in dff.columns:
        dff["sentiment_score"] = dff["sentiment"].apply(lambda x: 1 if x == "Positive" else 0)

    # 4) Weekly trend
    weekly = (
        dff.set_index("published_at")
           .resample("W")["sentiment_score"]
           .mean()
           .reset_index()
    )

    # 5) Weekly volume (some views may not have comment_id!)
    id_col = "comment_id" if "comment_id" in dff.columns else None
    if id_col:
        weekly_counts = (
            dff.set_index("published_at")
               .resample("W")[id_col]
               .count()
               .reset_index()
        )
        weekly_counts.rename(columns={id_col: "comment_count"}, inplace=True)
    else:
        # fallback: count rows
        weekly_counts = (
            dff.set_index("published_at")
               .resample("W")["sentiment_score"]
               .count()
               .reset_index()
               .rename(columns={"sentiment_score": "comment_count"})
        )

    # 6) Plots (safe even if weekly empty)
    if len(weekly) == 0:
        fig1 = empty_fig("Sentiment Trend (Weekly)")
    else:
        fig1 = plt.figure()
        plt.plot(weekly["published_at"], weekly["sentiment_score"], marker="o")
        plt.ylim(0, 1)
        plt.title("Sentiment Trend (Weekly)")
        plt.xlabel("Week")
        plt.ylabel("Avg Positive Sentiment")
        plt.xticks(rotation=30)
        plt.tight_layout()

    if len(weekly_counts) == 0:
        fig2 = empty_fig("Comment Volume (Weekly)")
    else:
        fig2 = plt.figure()
        plt.plot(weekly_counts["published_at"], weekly_counts["comment_count"], marker="o")
        plt.title("Comment Volume (Weekly)")
        plt.xlabel("Week")
        plt.ylabel("Comments")
        plt.xticks(rotation=30)
        plt.tight_layout()

    # 7) Top comments (safe if not enough rows)
    sort_col = "sentiment_confidence" if "sentiment_confidence" in dff.columns else ("like_count" if "like_count" in dff.columns else None)

    pos_df = dff[dff["sentiment"].astype(str).str.lower() == "positive"]
    neg_df = dff[dff["sentiment"].astype(str).str.lower() == "negative"]

    if sort_col:
        pos_df = pos_df.sort_values(sort_col, ascending=False)
        neg_df = neg_df.sort_values(sort_col, ascending=False)

    pos = pos_df.head(n)
    neg = neg_df.head(n)

    pos_text = "\n\n".join([f"üëç {t}" for t in pos["comment_text"].tolist()]) or "No positive comments for this filter."
    neg_text = "\n\n".join([f"üëé {t}" for t in neg["comment_text"].tolist()]) or "No negative comments for this filter."

    pct_pos = round(dff["sentiment_score"].mean() * 100, 1) if len(dff) else 0
    status = f"Video Type: {display_choice} | Rows: {len(dff)} | % Positive: {pct_pos}%"
    if warn: status += f" | {warn}"

    return fig1, fig2, pos_text, neg_text, status
# ======================
# 6) Gradio UI
# ======================
with gr.Blocks(title="Dyson Airwrap Sentiment Pulse") as demo:
    gr.Markdown("# Dyson Airwrap ‚Äì Consumer Sentiment Pulse")

    with gr.Row():
        video_type = gr.Dropdown(
            list(STANCE_LABELS.keys()),
            value="All Videos",
            label="Video Type"
        )
        n = gr.Slider(1, 10, value=2, step=1, label="Top comments to show")
        status = gr.Textbox(label="Status", interactive=False)

    trend_plot = gr.Plot(label="Sentiment Trend")
    volume_plot = gr.Plot(label="Comment Volume")

    with gr.Row():
        pos_box = gr.Textbox(label="Top Positive Comments", lines=8)
        neg_box = gr.Textbox(label="Top Negative Comments", lines=8)

    btn = gr.Button("Refresh")
    btn.click(fn=refresh, inputs=[video_type, n], outputs=[trend_plot, volume_plot, pos_box, neg_box, status])
    demo.load(fn=refresh, inputs=[video_type, n], outputs=[trend_plot, volume_plot, pos_box, neg_box, status])

demo.launch(share=True)

!pip -q install gradio pandas matplotlib supabase textblob

import gradio as gr
import pandas as pd
import matplotlib.pyplot as plt
from supabase import create_client
from textblob import TextBlob

# ======================
# 1) Supabase connection
# ======================
SUPABASE_URL = "https://bxqkumrkqsikzmlpatwd.supabase.co"
SUPABASE_KEY = "sb_publishable_YBO6o7OYfxde_hMSaB6cLA_48gcRXDe"
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# ======================
# 2) Load data
# ======================
def load_df():
    # Try a joined view first (if you have it), else fallback to comments
    for table in ["v_comments_joined", "comments"]:
        try:
            resp = supabase.table(table).select("*").execute()
            if resp.data and len(resp.data) > 0:
                dff = pd.DataFrame(resp.data)
                dff["__source__"] = table
                return dff
        except Exception:
            pass
    return pd.DataFrame()

df = load_df()
if len(df) == 0:
    raise ValueError("No data loaded from Supabase (tried v_comments_joined, comments).")

# Required columns for this app
REQUIRED = ["comment_text", "published_at"]
missing = [c for c in REQUIRED if c not in df.columns]
if missing:
    raise ValueError(f"Missing required columns in Supabase data: {missing}")

# Ensure comment_id exists (fallback if not in view)
if "comment_id" not in df.columns:
    df["comment_id"] = range(1, len(df) + 1)

# Parse datetime and drop invalid rows
df["published_at"] = pd.to_datetime(df["published_at"], errors="coerce")
df = df.dropna(subset=["published_at", "comment_text"]).copy()

# ======================
# 3) Sentiment (robust + tighter negatives)
# ======================
NEGATIVE_TRIGGERS = [
    "overpriced","not worth","waste","regret","returned","returning",
    "disappointed","hate","bad","useless","scam","rip off","ripoff",
    "doesn't work","didn't work","doesnt work","didnt work",
    "broke","broken","stopped working","burnt","burned",
    "too expensive","expensive","pricey",
    "hard to use","difficult","learning curve","confusing",
    "frizz","frizzy","damage","damaged","tangles","tangled"
]

POSITIVE_TRIGGERS = [
    "worth it","love","amazing","game changer","changed my life",
    "best","works great","so good","obsessed","recommend"
]

def compute_sentiment(text):
    t = str(text).lower()

    # Rule-based overrides
    if any(k in t for k in NEGATIVE_TRIGGERS):
        return "Negative"
    if any(k in t for k in POSITIVE_TRIGGERS):
        return "Positive"

    # Fallback to TextBlob (slightly stricter threshold)
    try:
        return "Positive" if TextBlob(text).sentiment.polarity > 0.05 else "Negative"
    except Exception:
        return "Negative"

# Apply sentiment ALWAYS (so we don't depend on DB having sentiment)
df["sentiment"] = df["comment_text"].apply(compute_sentiment)
df["sentiment_score"] = df["sentiment"].apply(lambda x: 1 if x == "Positive" else 0)

def negativity_strength(text):
    t = str(text).lower()
    return sum(1 for k in NEGATIVE_TRIGGERS if k in t)

# ======================
# 4) UI labels (professional)
# ======================
STANCE_LABELS = {
    "All Videos": None,
    "Supportive Reviews": "fanboy",
    "Skeptical Reviews": "critical"
}

def empty_fig(title: str, msg: str = "No data for this filter"):
    fig = plt.figure()
    plt.title(title)
    plt.text(0.5, 0.5, msg, ha="center", va="center")
    plt.axis("off")
    plt.tight_layout()
    return fig

def get_filtered_df(label):
    # If stance missing, disable filters gracefully
    if "stance" not in df.columns:
        return df.copy(), "‚ö†Ô∏è stance not available in this table/view (filter disabled)"

    raw = STANCE_LABELS.get(label, None)
    if raw is None:
        return df.copy(), None

    return df[df["stance"] == raw].copy(), None

# ======================
# 5) App logic
# ======================
def refresh(display_choice, n):
    n = int(n)

    dff, warn = get_filtered_df(display_choice)

    # Empty after filter
    if dff is None or len(dff) == 0:
        status = f"Video Type: {display_choice} | Rows: 0"
        if warn: status += f" | {warn}"
        return (
            empty_fig("Sentiment Trend (Weekly)"),
            empty_fig("Comment Volume (Weekly)"),
            "No positive comments for this filter.",
            "No negative comments for this filter.",
            status
        )

    # Ensure proper datetime + required cols
    dff["published_at"] = pd.to_datetime(dff["published_at"], errors="coerce")
    dff = dff.dropna(subset=["published_at", "comment_text"]).copy()

    if len(dff) == 0:
        status = f"Video Type: {display_choice} | Rows: 0 (no valid dated comments)"
        if warn: status += f" | {warn}"
        return (
            empty_fig("Sentiment Trend (Weekly)", "No valid dates"),
            empty_fig("Comment Volume (Weekly)", "No valid dates"),
            "No positive comments for this filter.",
            "No negative comments for this filter.",
            status
        )

    # Weekly trend
    weekly = (
        dff.set_index("published_at")
           .resample("W")["sentiment_score"]
           .mean()
           .reset_index()
    )

    # Weekly volume
    weekly_counts = (
        dff.set_index("published_at")
           .resample("W")["comment_id"]
           .count()
           .reset_index()
           .rename(columns={"comment_id": "comment_count"})
    )

    # Plot 1
    if len(weekly) == 0:
        fig1 = empty_fig("Sentiment Trend (Weekly)")
    else:
        fig1 = plt.figure()
        plt.plot(weekly["published_at"], weekly["sentiment_score"], marker="o")
        plt.ylim(0, 1)
        plt.title("Sentiment Trend (Weekly)")
        plt.xlabel("Week")
        plt.ylabel("Avg Positive Sentiment")
        plt.xticks(rotation=30)
        plt.tight_layout()

    # Plot 2
    if len(weekly_counts) == 0:
        fig2 = empty_fig("Comment Volume (Weekly)")
    else:
        fig2 = plt.figure()
        plt.plot(weekly_counts["published_at"], weekly_counts["comment_count"], marker="o")
        plt.title("Comment Volume (Weekly)")
        plt.xlabel("Week")
        plt.ylabel("Comments")
        plt.xticks(rotation=30)
        plt.tight_layout()

    # Top comments: prioritize "strong" positives/negatives, then like_count if available
    pos_df = dff[dff["sentiment"].str.lower() == "positive"].copy()
    neg_df = dff[dff["sentiment"].str.lower() == "negative"].copy()

    pos_df["pos_strength"] = pos_df["comment_text"].apply(
        lambda x: 1 if any(k in str(x).lower() for k in POSITIVE_TRIGGERS) else 0
    )
    neg_df["neg_strength"] = neg_df["comment_text"].apply(negativity_strength)

    if "like_count" in pos_df.columns:
        pos_df = pos_df.sort_values(["pos_strength", "like_count"], ascending=[False, False])
    else:
        pos_df = pos_df.sort_values(["pos_strength"], ascending=[False])

    if "like_count" in neg_df.columns:
        neg_df = neg_df.sort_values(["neg_strength", "like_count"], ascending=[False, False])
    else:
        neg_df = neg_df.sort_values(["neg_strength"], ascending=[False])

    pos = pos_df.head(n)
    neg = neg_df.head(n)

    pos_text = "\n\n".join([f"üëç {t}" for t in pos["comment_text"].tolist()]) or "No positive comments for this filter."
    neg_text = "\n\n".join([f"üëé {t}" for t in neg["comment_text"].tolist()]) or "No negative comments for this filter."

    pct_pos = round(dff["sentiment_score"].mean() * 100, 1) if len(dff) else 0
    status = f"Video Type: {display_choice} | Rows: {len(dff)} | % Positive: {pct_pos}%"
    if warn: status += f" | {warn}"

    return fig1, fig2, pos_text, neg_text, status

# ======================
# 6) Gradio UI
# ======================
with gr.Blocks(title="Dyson Airwrap Sentiment Pulse") as demo:
    gr.Markdown("# Dyson Airwrap ‚Äì Consumer Sentiment Pulse")

    with gr.Row():
        video_type = gr.Dropdown(
            choices=list(STANCE_LABELS.keys()),
            value="All Videos",
            label="Video Type"
        )
        n = gr.Slider(1, 10, value=2, step=1, label="Top comments to show")
        status = gr.Textbox(label="Status", interactive=False)

    trend_plot = gr.Plot(label="Sentiment Trend")
    volume_plot = gr.Plot(label="Comment Volume")

    with gr.Row():
        pos_box = gr.Textbox(label="Top Positive Comments", lines=8)
        neg_box = gr.Textbox(label="Top Negative Comments", lines=8)

    btn = gr.Button("Refresh")
    btn.click(fn=refresh, inputs=[video_type, n], outputs=[trend_plot, volume_plot, pos_box, neg_box, status])
    demo.load(fn=refresh, inputs=[video_type, n], outputs=[trend_plot, volume_plot, pos_box, neg_box, status])

demo.launch(share=True)